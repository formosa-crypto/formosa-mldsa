require "arithmetic/modular.jinc"

u256 INVERSE_OF_MODULUS_MOD_MONTGOMERY_R_VECTOR = (8u32)[
    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R,
    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R,
    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R,
    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R,
    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R,
    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R,
    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R,
    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R
];

u256 TWO_POW_22_VECTOR = (8u32)[
    1 << 22,
    1 << 22,
    1 << 22,
    1 << 22,
    1 << 22,
    1 << 22,
    1 << 22,
    1 << 22
];


namespace polynomial {
    fn add(reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] lhs_pointer rhs_pointer sum_pointer)
        -> reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL]
    {
        reg u256 lhs rhs sum;

        reg u64 offset;

        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            lhs = lhs_pointer.[u256 offset];
            rhs = rhs_pointer.[u256 offset];

            sum = #VPADD_8u32(lhs, rhs);
            sum_pointer.[u256 offset] = sum;

            offset += 32;
        }

        return sum_pointer;
    }

    fn subtract(
        reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] lhs_pointer rhs_pointer difference_pointer
    )
    -> reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] {
        reg u256 lhs rhs difference;

        reg u64 offset;

        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            lhs = lhs_pointer.[u256 offset];
            rhs = rhs_pointer.[u256 offset];

            difference = #VPSUB_8u32(lhs, rhs);
            difference_pointer.[u256 offset] = difference;

            offset += 32;
        }

        return difference_pointer;
    }

    inline
    fn add_to_running_total(reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] polynomial running_total)
        -> reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL]
    {
        reg u256 lhs rhs sum;

        reg u64 offset;

        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            lhs = polynomial.[u256 offset];
            rhs = running_total.[u256 offset];

            sum = #VPADD_8u32(lhs, rhs);
            running_total.[u256 offset] = sum;

            offset += 32;
        }

        return running_total;
    }

    inline
    fn zero(reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] polynomial)
        -> reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL]
    {
        reg u256 zero_u256;
        reg u64 offset;

        ?{}, zero_u256 = #set0_256();

        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            #VMOVDQU_256(polynomial.[u256 offset]) = zero_u256;
            offset += 32;
        }

        return polynomial;
    }

    fn pointwise_montgomery_multiply_and_reduce(
        reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] lhs rhs product
    ) -> reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL]
    {
        // TODO: If performance is lacking, unroll this loop to process 3 
        // chunks per round.

        reg u256 lhs_low lhs_high rhs_low rhs_high;
        reg u256 product_low product_high;
        reg u256 t_low t_high;

        reg u64 offset;

        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            lhs_low = lhs.[u256 offset];
            rhs_low = rhs.[u256 offset];

            lhs_high = #VMOVSHDUP_256(lhs_low);
            rhs_high = #VMOVSHDUP_256(rhs_low);

            // Multiply
            product_low = #VPMUL_256(lhs_low, rhs_low);
            product_high = #VPMUL_256(lhs_high, rhs_high);

            // Reduce
            t_low = #VPMUL_256(product_low,
                    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R_VECTOR);
            t_high = #VPMUL_256(product_high,
                    INVERSE_OF_MODULUS_MOD_MONTGOMERY_R_VECTOR);
            t_low = #VPMUL_256(t_low, MODULUS_VECTOR);
            t_high = #VPMUL_256(t_high, MODULUS_VECTOR);

            product_low = #VPSUB_4u64(product_low, t_low);
            product_high = #VPSUB_4u64(product_high, t_high);

            product_low = #VMOVSHDUP_256(product_low);
            product_low = #VPBLEND_8u32(product_low, product_high, 0b1_0_1_0_1_0_1_0);
            product.[u256 offset] = product_low;

            offset += 32;
        }

        return product;
    }

    fn conditionally_add_modulus(reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] polynomial)
        -> reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL]
    {
        reg u256 zero mask;
        reg u256 lhs rhs;
        reg u256 modulus;
        reg u64 offset;

        modulus = MODULUS_VECTOR;

        ?{}, zero = #set0_256();

        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            lhs = polynomial.[u256 offset];

            mask = #VPCMPGT_8u32(zero, lhs);
            rhs = #VPAND_256(modulus, mask);

            lhs = #VPADD_8u32(lhs, rhs);
            polynomial.[u256 offset] = lhs;

            offset += 32;
        }

        return polynomial;
    }

    inline
    fn check_infinity_norm(
        reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] polynomial,
        inline int threshold
    ) -> reg u8
    {
        reg u256 coefficients;
        reg u256 zero threshold_vector;
        reg u256 exceeds exceeds_any;
        reg u32 msb_mask;
        reg u8 result;
        reg bool zf;

        reg u64 offset temp;

        temp = threshold - 1;
        threshold_vector = (256u)#VMOV(temp);
        threshold_vector = #VPBROADCAST_8u32(threshold_vector);

        ?{}, zero = #set0_256();
        ?{}, exceeds_any = #set0_256();

        result = 0;
        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            coefficients = polynomial.[u256 offset];

            coefficients = #VPABS_8u32(coefficients);
            exceeds = #VPCMPGT_8u32(coefficients, threshold_vector);

            exceeds_any = #VPOR_256(exceeds_any, exceeds);

            offset += 32;
        }

        msb_mask = #VPMOVMSKB_u256u32(exceeds_any);
        _, _, _, _, zf = #TEST_32(msb_mask, msb_mask);
        result = #SETcc(!zf);

        return result;
    }

    inline
    fn make_hint(
        reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] low_coefficients high_coefficients,
        #spill_to_mmx reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] hints
    ) -> reg u32, reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL]
    {
        reg u256 hint_block;
        reg u256 low abs_low high;
        reg u256 gamma2 minus_gamma2;
        reg u256 low_out_of_bounds;
        reg u256 low_equals_minus_gamma2_and_high_is_nonzero;
        reg u256 zeros;

        reg u64 offset temp;
        reg u32 num_hints weight;

        temp = GAMMA2;
        gamma2 = (256u)#VMOV_64(temp);
        gamma2 = #VPBROADCAST_8u32(gamma2);

        temp = -GAMMA2;
        minus_gamma2 = (256u)#VMOV_64(temp);
        minus_gamma2 = #VPBROADCAST_8u32(minus_gamma2);

        ?{}, zeros = #set0_256();

        weight = 0;
        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            low = low_coefficients.[u256 offset];
            high = high_coefficients.[u256 offset];

            abs_low = #VPABS_8u32(low);
            low_out_of_bounds = #VPCMPGT_8u32(abs_low, gamma2);

            low_equals_minus_gamma2_and_high_is_nonzero = #VPCMPEQ_8u32(low, minus_gamma2);
            low_equals_minus_gamma2_and_high_is_nonzero =
                #VPSIGN_8u32(
                    low_equals_minus_gamma2_and_high_is_nonzero,
                    high);

            hint_block = #VPOR_256(
                low_out_of_bounds,
                low_equals_minus_gamma2_and_high_is_nonzero
            );

            // TODO: We could also handle serializing the hint here, but
            // that'd require _mm256_movemask_ps(). Revisit if performance
            // is lacking.
            hint_block = #VPSRL_8u32(hint_block, 31);
            hints.[u256 offset] = hint_block;
            offset += 32;

            // TODO: The code:
            // zeros = #VPSUB_8u32(zeros, hint_block);
            // num_hints = #VPMOVMSKB_u256u32(zeros);
            // causes a bug. Figure out why.
            hint_block = #VPSUB_8u32(zeros, hint_block);
            num_hints = #VPMOVMSKB_u256u32(hint_block);
            _, _, _, _, _, num_hints = #POPCNT_32(num_hints);
            num_hints >>= 2;

            weight += num_hints;
        }

        return weight, hints;
    }

    fn reduce32(reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] polynomial)
        -> reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL]
    {
        reg u256 two_pow_22 modulus;
        reg u256 a t;

        reg u64 offset;

        two_pow_22 = #VMOVDQU_256(TWO_POW_22_VECTOR);
        modulus = #VMOVDQU_256(MODULUS_VECTOR);

        offset = 0;
        while(offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            // t = (a + (1 << 22)) >> 23
            a = polynomial.[u256 offset];
            t = #VPADD_8u32(a, two_pow_22);
            t = #VPSRA_8u32(t, 23);

            // t = a - t*Q
            t = #VPMULL_8u32(t, modulus);
            a = #VPSUB_8u32(a, t);

            polynomial.[u256 offset] = a;

            offset += 32;
        }

        return polynomial;
    }

    inline
    fn shift_coefficients_left(reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] polynomial) -> reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] {
        reg u256 coefficients;

        reg u64 offset;

        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            coefficients = polynomial.[u256 offset];
            coefficients = #VPSLL_8u32(coefficients, BITS_IN_LOWER_PART_OF_T);

            polynomial.[u256 offset] = coefficients;

            offset += 32;
        }

        return polynomial;
    }

    inline
    fn power2round(
        reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] polynomial,
        reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] highbits,
        reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL] lowbits
    ) -> reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL],
         reg ptr u32[COEFFICIENTS_IN_POLYNOMIAL]
    {
        reg u256 coefficients;
        reg u256 high low;
        reg u256 half_t0_bits ones_vector;

        reg u64 offset temp;

        half_t0_bits = HALF_OF_BITS_IN_T0_VECTOR;

        temp = 1;
        ones_vector = (256u)#VMOV_64(temp);
        ones_vector = #VPBROADCAST_8u32(ones_vector);

        offset = 0;
        while (offset < COEFFICIENTS_IN_POLYNOMIAL * 4) {
            coefficients = polynomial.[u256 offset];

            high = #VPADD_8u32(coefficients, half_t0_bits);
            high = #VPSUB_8u32(high, ones_vector);
            high = #VPSRA_8u32(high, BITS_IN_LOWER_PART_OF_T);

            low = #VPSLL_8u32(high, BITS_IN_LOWER_PART_OF_T);
            low = #VPSUB_8u32(coefficients, low);

            highbits.[u256 offset] = high;
            lowbits.[u256 offset] = low;

            offset += 32;
        }

        return highbits, lowbits;
    }
}
