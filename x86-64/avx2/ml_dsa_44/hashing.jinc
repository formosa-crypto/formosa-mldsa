// N.B.: While this is only used in hash_verification_key(), making it an inline int
// wouldn't work; it's used in a while loop condition, which causes issues for
// the RSB-checker.
param int FULL_BLOCKS_IN_VERIFICATION_KEY = VERIFICATION_KEY_SIZE / SHAKE256_RATE;
fn hash_verification_key(
    #spill_to_mmx reg ptr u8[VERIFICATION_KEY_HASH_SIZE] verification_key_hash,
    #spill_to_mmx reg ptr u8[VERIFICATION_KEY_SIZE] verification_key
) -> reg ptr u8[VERIFICATION_KEY_HASH_SIZE]
{
    reg u256[7] state;
    #spill_to_mmx reg u64 verification_key_offset;

    reg u64 t64;
    reg u256 r0, r1, r2, r3, r4, r5, r6;
    reg u128 t128_0, t128_1;

    // Absorb ...

    state = __state_init_avx2();

    // N.B.: VERIFICATION_KEY_SIZE for:
    //
    // ML-DSA-44: 1312 = SHAKE256_RATE * 9 + 88
    //
    verification_key_offset = 0;
    while(verification_key_offset < FULL_BLOCKS_IN_VERIFICATION_KEY * SHAKE256_RATE) {
        state = shake256_absorb_block(state, verification_key[verification_key_offset : SHAKE256_RATE]);
        verification_key_offset += SHAKE256_RATE;
    }

    // Now absorb the last partial block.
    reg ptr u8[88] block = verification_key[verification_key_offset:88];

    t64 = block.[:u64 0];
    t128_0 = (128u) t64;
    r0 = #VPBROADCAST_4u64(t128_0);
    state[0] ^= r0;

    r1 = block.[:u256 8];
    state[1] ^= r1;

    t64 = block.[:u64 40];
    t128_1 = (128u) t64;

    r3 = block.[:u256 48];

    t64 = block.[:u64 80];
    t128_0 = (128u) t64;

    r4 = #set0_256();

    t64 = 0;
    t128_1 = #VPINSR_2u64(t128_1, t64, 1);

    r5 = #set0_256();

    t64 = 0;
    t128_0 = #VPINSR_2u64(t128_0, t64, 1);
    r2 = (2u128)[t128_1, t128_0];
    state[2] ^= r2;

    r6 = #set0_256();

    state = __addstate_r3456_avx2(state, r3, r4, r5, r6);

    // Finally, add the trail bit.
    t64 = 0x1f;
    r2 = (256u)#VMOV_64(t64);
    state[4] ^= r2;

    state = shake256_add_rate_bit(state);

    // ... then squeeze.
    state = _keccakf1600_avx2(state);

    // VERIFICATION_KEY_HASH_SIZE is always 64.
    verification_key_hash = squeeze_64_bytes(verification_key_hash, state);

    return verification_key_hash;
}

// The message representative is always 64 bytes long, which means the first
// full block that we absorb will contain 64 bytes of the message representative,
// and SHAKE256_RATE - 64 = 136 - 64 = 72 bytes of the encoded commitment.
// Subtracting these 72 bytes from the encoded commitment size and dividing
// by SHAKE256_RATE gives us the number of full commitment blocks to absorb.
param int FULL_COMMITMENT_BLOCKS_TO_ABSORB = (ENCODED_COMMITMENT_SIZE - 72) / SHAKE256_RATE;

inline
fn __derive_commitment_hash(
    reg ptr u8[64] message_representative,
    #spill_to_mmx reg ptr u8[ENCODED_COMMITMENT_SIZE] encoded_commitment
) -> stack u8[COMMITMENT_HASH_SIZE]
{
    stack u8[COMMITMENT_HASH_SIZE] commitment_hash;

    reg u256[7] state;
    stack u8[SHAKE256_RATE] initial_block;

    reg u64 copied_8_bytes;
    #spill_to_mmx reg u64 encoded_commitment_offset;

    reg u256 copied_32_bytes;

    reg u64 t64;
    reg u128 t128;
    reg u256 r0;

    // Absorb message_representative (always 64 bytes)
    copied_32_bytes = message_representative.[:u256 0];
    initial_block.[:u256 0] = copied_32_bytes;

    copied_32_bytes = message_representative.[:u256 32];
    initial_block.[:u256 32] = copied_32_bytes;

    // The ENCODED_COMMITMENT_SIZE for ML-DSA-44 is 768. Now absorb the first
    // 72 bytes of the commitment.
    copied_32_bytes = encoded_commitment.[:u256 0];
    initial_block.[:u256 64] = copied_32_bytes;

    copied_32_bytes = encoded_commitment.[:u256 32];
    initial_block.[:u256 96] = copied_32_bytes;

    copied_8_bytes = encoded_commitment.[:u64 64];
    initial_block.[:u64 128] = copied_8_bytes;

    // We have SHAKE256_RATE bytes in the state, permute
    state = __state_init_avx2();

    state = shake256_absorb_block(state, initial_block);

    // For each parameter set we have the following bytes left to absorb.
    //
    // ML-DSA-44: 768 - 72 = 696 = SHAKE256_RATE * 5 + 16
    // ML-DSA-65: 768 - 72 = 696 = SHAKE256_RATE * 5 + 16
    // ML-DSA-87: 1024 - 72 = 952 = SHAKE256_RATE * 7
    //
    // Now absorb all the full blocks in the encoded commitment (note that
    // (for ML-DSA-87 this is all of the remaining commitment).
    //
    encoded_commitment_offset = 72;
    while(encoded_commitment_offset < FULL_COMMITMENT_BLOCKS_TO_ABSORB * SHAKE256_RATE) {
        state = shake256_absorb_block(state, encoded_commitment[encoded_commitment_offset : SHAKE256_RATE]);
        encoded_commitment_offset += SHAKE256_RATE;
    }

    // Finally, we should have 16 bytes left to absorb.
    reg ptr u8[16] block = encoded_commitment[encoded_commitment_offset:16];

    t64 = block.[:u64 0];
    t128 = (128u)t64;
    r0 = #VPBROADCAST_4u64(t128);
    state[0] ^= r0;

    t64 = block.[:u64 8];

    t128 = #VMOV(t64);

    t64 = 0x1f;
    t128 = #VPINSR_2u64(t128, t64, 1);

    r0 = #set0_256();
    r0 = #VINSERTI128(r0, t128, 0);

    state[1] ^= r0;

    state = shake256_add_rate_bit(state);

    // Now squeeze
    state = _keccakf1600_avx2(state);

    // COMMITMENT_HASH_SIZE is 32
    // state[0] = [0, 0, 0, 0]
    t128 = (128u)state[0];
    commitment_hash.[:u64 0] = t128;

    // [ 1, 2, 3, 4 ]
    t128 = (128u)state[1];
    commitment_hash.[:u128 8] = t128;

    t128 = #VEXTRACTI128(state[1], 1);
    commitment_hash.[:u64 24] = t128;

    return commitment_hash;
}
