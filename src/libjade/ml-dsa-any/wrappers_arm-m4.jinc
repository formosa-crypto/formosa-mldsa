/*************************************************
*
* Description: Provide wrappers around functions that have
*              architecture specific implementations
*
* Version : ARM-V7m
*
**************************************************/

/* ********************************************************************** */
/* Helper functions to facilitate architecture modularity                 */

inline fn __store_imm(inline int imm) -> reg u32 {
  reg u32 out;
  out = imm;
  return out;
}

inline fn __add_large_imm(reg u32 in, inline int imm) -> reg u32 {
  reg u32 out;
  out = in + imm;
  return out;
}

inline fn __imm_sub_reg_inplace(inline int imm, reg u32 in) -> reg u32 {
    in = imm - in;
    return in;
}

inline fn __imm_sub_reg(inline int imm, reg u32 in) -> reg u32 {
    reg u32 out;
    out = imm - in;
    return out;
}

inline fn __set_if_true(reg u32 in, inline bool b) -> reg u32 {
  reg u32 out;
  out = in if b;
  return out;
}

inline fn __set_if_true_plus_imm(reg u32 in, inline int i, inline bool b) -> reg u32 {
  reg u32 out;
  out = in + i if b;
  return out;
}

inline fn __cmp_ge_s(reg u32 in_1, reg u32 in_2) -> inline bool { 
  inline bool b;
  ?{">=s" = b} = #CMP(in_1, in_2);
  return b;
} 

inline fn __cmp_gt_u(reg u32 in_1, reg u32 in_2) -> inline bool { 
  inline bool b;
  ?{">u" = b} = #CMP(in_1, in_2);
  return b;
} 

inline fn __cmp_lt_u_imm(inline u32 in_1, reg u32 in_2) -> inline bool { 
  inline bool b;
  ?{">u"=b} = #CMP(in_2, in_1); 
  return b;
}

// TODO: rename and document 
inline fn __cmp_b(reg u32 in_1, reg u32 in_2) -> inline bool {
  inline bool b;
  ?{"<u" = b} = #CMP(in_1, in_2);
  return b;
}



inline fn __cmp_eq_lt(reg u32 in_1, reg u32 in_2) -> inline bool, inline bool {
  inline bool lt;
  inline bool eq;
  ?{"==" = eq, "<s" = lt} = #CMP(in_1, in_2);
  return eq, lt;
}

inline fn __cmp_gt_le_zero(reg u32 in) -> inline bool, inline bool {
  inline bool gt;
  inline bool le;
  ?{">s" = gt, "<=s" = le} = #CMP(in, 0);
  return gt, le;
}

inline fn __ubfx(reg u32 in, inline int pos, inline int width) -> reg u32 {
  in = #UBFX(in, pos, width);
  return in;
}

inline fn __smull(reg u32 in_1, reg u32 in_2, reg u32 out_low, reg u32 out_high) -> reg u32, reg u32 {
  out_high, out_low = #SMULL(in_1, in_2);
  return out_low, out_high;
}

/**
 Operates the or operation of the @nb_bits logical left shift on @in_2 with @in_1.
 Writes the result in @in_1.
 Introduces a temporary register.
**/
inline fn __or_lsl_inplace(reg u32 in_1, reg u32 in_2, inline int nb_bits) -> reg u32 {
  in_1 |= (in_2 << nb_bits);
  return in_1;
}

/**
 Operates the or of the @nb_bits logical left shift on @in_2 with @in_1.
 Writes the result in @out.
**/
inline fn __or_lsl(reg u32 in_1, reg u32 in_2, inline int nb_bits) -> reg u32 {
  reg u32 out;
  out = in_1 | (in_2 << nb_bits);
  return out;
}

/**
 Operates the and of the @nb_bits arithmetic right shift on @in_2 with @in_1.
**/
inline fn __and_asr(reg u32 in_1, reg u32 in_2, inline int nb_bits) -> reg u32 {
  reg u32 out;
  out = in_1 & (in_2 >>s nb_bits);
  return out;
}

/**
 Operates the addition of the @nb_bits logical left shift on @in_2 with @in_1.
 Writes the result in @in_1.
 Introduces a temporary register.
**/
inline fn __plus_lsl_inplace(reg u32 in_1, reg u32 in_2, inline int nb_bits) -> reg u32 {
  in_1 += (in_2 << nb_bits);
  return in_1;
}


/**
 Operates the addition of the @nb_bits logical left shift on @in_2 with @in_1.
**/
inline fn __plus_lsl(reg u32 in_1, reg u32 in_2, inline int nb_bits) -> reg u32 {
  reg u32 out;
  out = in_1 +  (in_2 << nb_bits);
  return out;
}

/**
 Operates the subtraction of @in_1 with the @nb_bits logical left shift on @in_2.
 Writes the result in @out.
**/
inline fn __sub_lsl(reg u32 in_1, reg u32 in_2, inline int nb_bits) -> reg u32 {
  reg u32 out;
  out = in_1 - (in_2 << nb_bits);
  return out;
}

/**
 Operates the subtraction of the @nb_bits logical left shift on @in_2 with @in_1.
 Writes the result in @out.
**/
inline fn __rsub_lsl(reg u32 in_1, inline int in_2, inline int nb_bits) -> reg u32 {
  reg u32 out;
  out = (in_2 << nb_bits) - in_1;
  return out;
}

/**
 Operates the subtraction of the @nb_bits logical left shift on @in_2 with @in_1.
 Writes the result in @in_2.
**/
inline fn __rsb_lsl_inplace(reg u32 in_1, reg u32 in_2, inline int nb_bits) -> reg u32 {
  in_2 = #RSB(in_1, in_2 << nb_bits);
  return in_2;
}

/**
 Operates the subtraction of the @nb_bits logical left shift on @in_2 with @in_1.
 Writes the result in @out.
**/
inline fn __rsb_lsl(reg u32 in_1, reg u32 in_2, inline int nb_bits) -> reg u32 {
  reg u32 out;
  out = #RSB(in_1, in_2 << nb_bits);
  return out;
}


/** 
**/
inline fn __abs_ct(#secret reg u32 x) -> reg u32 { 
  x = -x if (x <s 0);
  return x;
}
